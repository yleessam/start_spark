{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b589fafa-ad21-49bc-a33d-11f9ff3a7b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://47f2e7cfa306:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>classificationExample1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb2c9fa8e90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"classificationExample1\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a94f33-a509-4171-80d2-5e504b7fc72d",
   "metadata": {},
   "source": [
    "# 타이타닉 데이터를 이용한 생존여부 예측 모델\n",
    "## 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "709e4481-f782-472c-8812-18f3bee65fde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|Gender| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일 로드\n",
    "data = spark.read.csv(\"learning_spark_data/titanic.csv\", \n",
    "                      header=True, \n",
    "                      inferSchema=True)\n",
    "# 데이터 확인\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d3f2de7-710e-42a3-95de-e95f8778dcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+------+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Gender|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+------+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|     0|177|    0|    0|     0|   0|  687|       2|\n",
      "+-----------+--------+------+----+------+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum, when, isnan\n",
    "\n",
    "## 결측치 처리\n",
    "null_counts = data.select(\n",
    "                    [\n",
    "                        sum( when(col(c).isNull() | isnan(c),1).otherwise(0) ).alias(c)\n",
    "                        for c in data.columns\n",
    "                    ]\n",
    "                )\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7915976-5b36-492e-9192-fc92695ad9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+\n",
      "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|\n",
      "+--------+------+------+----+-----+-----+-------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|\n",
      "+--------+------+------+----+-----+-----+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "data_1 = data.select('Survived', 'Pclass', 'Gender', 'Age', 'SibSp', 'Parch','Fare' )\n",
    "data_1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efe7b042-d84e-421d-97e7-69e3650db771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#age 결측치 처리 - 평균값으로 대체\n",
    "mean_age = data_1.select('Age').agg( {\n",
    "                    \"Age\":\"mean\"\n",
    "                } ).collect()[0][0]\n",
    "mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab31308-c42f-4c39-a831-d88288a92614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+-----------------+-----+-----+-------+\n",
      "|Survived|Pclass|Gender|              Age|SibSp|Parch|   Fare|\n",
      "+--------+------+------+-----------------+-----+-----+-------+\n",
      "|       0|     3|  male|             22.0|    1|    0|   7.25|\n",
      "|       1|     1|female|             38.0|    1|    0|71.2833|\n",
      "|       1|     3|female|             26.0|    0|    0|  7.925|\n",
      "|       1|     1|female|             35.0|    1|    0|   53.1|\n",
      "|       0|     3|  male|             35.0|    0|    0|   8.05|\n",
      "|       0|     3|  male|29.69911764705882|    0|    0| 8.4583|\n",
      "|       0|     1|  male|             54.0|    0|    0|51.8625|\n",
      "|       0|     3|  male|              2.0|    3|    1| 21.075|\n",
      "|       1|     3|female|             27.0|    0|    2|11.1333|\n",
      "|       1|     2|female|             14.0|    1|    0|30.0708|\n",
      "+--------+------+------+-----------------+-----+-----+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_1 = data_1.fillna({'Age': mean_age})\n",
    "data_1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16a0e647-d73d-4f10-9fc6-4feddb9ae600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bfe7bea-2714-4677-a02f-c1c44fa8ca77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+----------+\n",
      "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|SexIndexer|\n",
      "+--------+------+------+----+-----+-----+-------+----------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|       0.0|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|       1.0|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|       1.0|\n",
      "|       1|     1|female|35.0|    1|    0|   53.1|       1.0|\n",
      "|       0|     3|  male|35.0|    0|    0|   8.05|       0.0|\n",
      "+--------+------+------+----+-----+-----+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 인코딩 StringIndexer\n",
    "indexer = StringIndexer( inputCol='Gender', outputCol='SexIndexer')\n",
    "data_1 = indexer.fit(data_1).transform(data_1)\n",
    "data_1.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbb9bc29-fda7-4814-851c-2b937525f115",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|            features|Survived|\n",
      "+--------------------+--------+\n",
      "|[3.0,0.0,22.0,1.0...|       0|\n",
      "|[1.0,1.0,38.0,1.0...|       1|\n",
      "|[3.0,1.0,26.0,0.0...|       1|\n",
      "|[1.0,1.0,35.0,1.0...|       1|\n",
      "|[3.0,0.0,35.0,0.0...|       0|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FeatureVector 생성\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['Pclass', 'SexIndexer', 'Age', 'SibSp', 'Parch','Fare' ],\n",
    "    outputCol='features'\n",
    ")\n",
    "data_1 = assembler.transform(data_1)\n",
    "data_1.select('features','Survived').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1706335-cebe-42fa-bda1-89bb3e6c38ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+------+----------+--------------------+\n",
      "|Survived|Pclass|Gender| Age|SibSp|Parch|  Fare|SexIndexer|            features|\n",
      "+--------+------+------+----+-----+-----+------+----------+--------------------+\n",
      "|       0|     1|female| 2.0|    1|    2|151.55|       1.0|[1.0,1.0,2.0,1.0,...|\n",
      "|       0|     1|female|25.0|    1|    2|151.55|       1.0|[1.0,1.0,25.0,1.0...|\n",
      "|       0|     1|  male|18.0|    1|    0| 108.9|       0.0|[1.0,0.0,18.0,1.0...|\n",
      "|       0|     1|  male|19.0|    1|    0|  53.1|       0.0|[1.0,0.0,19.0,1.0...|\n",
      "|       0|     1|  male|19.0|    3|    2| 263.0|       0.0|[1.0,0.0,19.0,3.0...|\n",
      "+--------+------+------+----+-----+-----+------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+------+------+-----------------+-----+-----+-------+----------+--------------------+\n",
      "|Survived|Pclass|Gender|              Age|SibSp|Parch|   Fare|SexIndexer|            features|\n",
      "+--------+------+------+-----------------+-----+-----+-------+----------+--------------------+\n",
      "|       0|     1|female|             50.0|    0|    0|28.7125|       1.0|[1.0,1.0,50.0,0.0...|\n",
      "|       0|     1|  male|             21.0|    0|    1|77.2875|       0.0|[1.0,0.0,21.0,0.0...|\n",
      "|       0|     1|  male|             24.0|    0|    0|   79.2|       0.0|[1.0,0.0,24.0,0.0...|\n",
      "|       0|     1|  male|             29.0|    0|    0|   30.0|       0.0|[1.0,0.0,29.0,0.0...|\n",
      "|       0|     1|  male|29.69911764705882|    0|    0|  26.55|       0.0|[1.0,0.0,29.69911...|\n",
      "+--------+------+------+-----------------+-----+-----+-------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 분할\n",
    "train_data, test_data = data_1.randomSplit([0.8,0.2], seed=42)\n",
    "train_data.show(5), test_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "998e1779-e960-4d99-b70a-6fa5abb6ac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+----------+\n",
      "|            features|Survived|prediction|\n",
      "+--------------------+--------+----------+\n",
      "|[1.0,1.0,50.0,0.0...|       0|       1.0|\n",
      "|[1.0,0.0,21.0,0.0...|       0|       1.0|\n",
      "|[1.0,0.0,24.0,0.0...|       0|       1.0|\n",
      "|[1.0,0.0,29.0,0.0...|       0|       1.0|\n",
      "|[1.0,0.0,29.69911...|       0|       1.0|\n",
      "+--------------------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='Survived')\n",
    "lr_model = lr.fit(train_data)\n",
    "predic = lr_model.transform(test_data)\n",
    "predic.select('features', 'Survived', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f28ce019-f822-46ee-8911-780c2f6f2322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----+\n",
      "|Survived|prediction|count|\n",
      "+--------+----------+-----+\n",
      "|       1|       0.0|   16|\n",
      "|       0|       0.0|   72|\n",
      "|       1|       1.0|   45|\n",
      "|       0|       1.0|   12|\n",
      "+--------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predic.select('Survived','prediction').groupBy('Survived','prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72db03ec-6b35-4d2f-a77b-35526900a4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "comp = predic.withColumn('correct', expr('case when Survived = prediction then 1 else 0 end'))\n",
    "comp.where('correct=0').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "315540ac-ba30-46f4-8ab6-27b45b76f85c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+-----------------+-----+-----+--------+----------+--------------------+--------------------+--------------------+----------+\n",
      "|Survived|Pclass|Gender|              Age|SibSp|Parch|    Fare|SexIndexer|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+------+------+-----------------+-----+-----+--------+----------+--------------------+--------------------+--------------------+----------+\n",
      "|       0|     1|female|             50.0|    0|    0| 28.7125|       1.0|[1.0,1.0,50.0,0.0...|[-1.9520233772457...|[0.12433289705143...|       1.0|\n",
      "|       0|     1|  male|             21.0|    0|    1| 77.2875|       0.0|[1.0,0.0,21.0,0.0...|[-0.5063625084573...|[0.37604662481402...|       1.0|\n",
      "|       0|     1|  male|             24.0|    0|    0|    79.2|       0.0|[1.0,0.0,24.0,0.0...|[-0.5000095386390...|[0.37753842718518...|       1.0|\n",
      "|       0|     1|  male|             29.0|    0|    0|    30.0|       0.0|[1.0,0.0,29.0,0.0...|[-0.1615540822042...|[0.45969909487698...|       1.0|\n",
      "|       0|     1|  male|29.69911764705882|    0|    0|   26.55|       0.0|[1.0,0.0,29.69911...|[-0.1231782413911...|[0.46924431750958...|       1.0|\n",
      "|       0|     1|  male|29.69911764705882|    0|    0|    31.0|       0.0|[1.0,0.0,29.69911...|[-0.1347897264619...|[0.46635349453316...|       1.0|\n",
      "|       0|     1|  male|29.69911764705882|    0|    0|221.7792|       0.0|[1.0,0.0,29.69911...|[-0.6325941832296...|[0.34692254756630...|       1.0|\n",
      "|       0|     3|female|              9.0|    1|    1| 15.2458|       1.0|[3.0,1.0,9.0,1.0,...|[-0.8294985925619...|[0.30375110057917...|       1.0|\n",
      "|       0|     3|female|             14.0|    0|    0|  7.8542|       1.0|[3.0,1.0,14.0,0.0...|[-1.1048782816873...|[0.24882696769997...|       1.0|\n",
      "|       0|     3|female|             22.0|    0|    0| 10.5167|       1.0|[3.0,1.0,22.0,0.0...|[-0.7757027387564...|[0.31524678240576...|       1.0|\n",
      "|       0|     3|female|             28.0|    1|    1|    14.4|       1.0|[3.0,1.0,28.0,1.0...|[-0.0289998254718...|[0.49275055168429...|       1.0|\n",
      "|       0|     3|female|29.69911764705882|    0|    0|  8.1375|       1.0|[3.0,1.0,29.69911...|[-0.4460134544155...|[0.39030901997152...|       1.0|\n",
      "|       1|     1|  male|             40.0|    0|    0|    31.0|       0.0|[1.0,0.0,40.0,0.0...|[0.29800553338314...|[0.57395488063056...|       0.0|\n",
      "|       1|     1|  male|             42.0|    0|    0| 26.2875|       0.0|[1.0,0.0,42.0,0.0...|[0.39433268162065...|[0.59732526764030...|       0.0|\n",
      "|       1|     1|  male|             45.0|    0|    0|   26.55|       0.0|[1.0,0.0,45.0,0.0...|[0.51969380848810...|[0.62707616571001...|       0.0|\n",
      "|       1|     2|  male|              2.0|    1|    1|    26.0|       0.0|[2.0,0.0,2.0,1.0,...|[0.37184806510138...|[0.59190546052286...|       0.0|\n",
      "|       1|     3|female|29.69911764705882|    2|    0|   23.25|       1.0|[3.0,1.0,29.69911...|[0.29463470411987...|[0.57313040472105...|       0.0|\n",
      "|       1|     3|female|             33.0|    3|    0|   15.85|       1.0|[3.0,1.0,33.0,3.0...|[0.84267221664326...|[0.69902771706049...|       0.0|\n",
      "|       1|     3|female|             38.0|    1|    5| 31.3875|       1.0|[3.0,1.0,38.0,1.0...|[0.80563898861163...|[0.69117942146816...|       0.0|\n",
      "|       1|     3|female|             63.0|    0|    0|  9.5875|       1.0|[3.0,1.0,63.0,0.0...|[0.94935152197948...|[0.72098474515652...|       0.0|\n",
      "+--------+------+------+-----------------+-----+-----+--------+----------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 틀린 데이터만 필터링\n",
    "predic.filter( col('Survived') != col('prediction')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "135ead49-a2a6-4ea2-b928-a26814843844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8068965517241379"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도 평가\n",
    "comp.selectExpr('avg(correct) as accuracy').collect()[0]['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "258702ec-f9f8-4b36-b06d-2c2889206c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8664129586260734"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "eval = BinaryClassificationEvaluator(labelCol='Survived',\n",
    "                                     rawPredictionCol='rawPrediction',\n",
    "                                     metricName='areaUnderROC')\n",
    "auc = eval.evaluate(predic)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04788aa8-523b-4851-b0c5-2b5a552942a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUROC -> X축 FPR, y축 TPR 의 곡선 아래면적, 1에 가까울 수록 좋은 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b99f367-ea99-46a9-b5bd-2bea1da6b780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd90723-d751-4ec2-b603-062934cbce8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1a526-3abb-4753-8d68-6e8d15882af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42ebae-d14a-42a5-be11-90d0521b11a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
