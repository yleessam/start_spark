{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48140c7d-47f9-4123-9c87-2fe0d9a6280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#08_02_Regression.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3b8ee3a-0e36-46df-a937-5c6cf20a33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "MAX_MEMORY = '8g'\n",
    "spark = SparkSession.builder.appName(\"taxi-fare-prediciton_2nd\")\\\n",
    "            .config('spark.driver.memory', MAX_MEMORY)\\\n",
    "            .config('spark.executor.memory', MAX_MEMORY)\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee921107-6d8e-4db5-ab23-50b6a6f30c14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "trip_data_path = os.path.join(cwd, 'learning_spark_data', 'trips', '*.csv')\n",
    "file_path = f\"file:///{trip_data_path.replace(os.sep,'/') }\"\n",
    "trip_df = spark.read.csv(file_path, inferSchema=True, header=True)\n",
    "trip_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e631ef00-27b6-472f-950e-37831964bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a7d3919-0fd5-4e87-9590-6842fadbacc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_df.createOrReplaceTempView('trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1a66c7-a54a-4c76-8bd8-7a2ec70c461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    passenger_count,\n",
    "    PULocationID as pickup_location_id,\n",
    "    DOLocationID as dropoff_location_id,\n",
    "    trip_distance,\n",
    "    HOUR(tpep_pickup_datetime) as pickup_time,\n",
    "    DATE_FORMAT(TO_DATE(tpep_pickup_datetime), 'EEEE') AS day_of_week,\n",
    "    total_amount\n",
    "FROM\n",
    "    trips\n",
    "WHERE\n",
    "    total_amount < 5000\n",
    "    AND total_amount > 0\n",
    "    AND trip_distance > 0\n",
    "    AND trip_distance < 500\n",
    "    AND passenger_count < 4\n",
    "    AND TO_DATE(tpep_pickup_datetime) >= '2021-01-01'\n",
    "    AND TO_DATE(tpep_pickup_datetime) < '2021-08-01'\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3455a29-f725-400e-afbb-91f67cd53915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "|passenger_count|pickup_location_id|dropoff_location_id|trip_distance|pickup_time|day_of_week|total_amount|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "|              0|               138|                265|         16.5|          0|     Monday|       70.07|\n",
      "|              1|                68|                264|         1.13|          0|     Monday|       11.16|\n",
      "|              1|               239|                262|         2.68|          0|     Monday|       18.59|\n",
      "|              1|               186|                 91|         12.4|          0|     Monday|        43.8|\n",
      "|              2|               132|                265|          9.7|          0|     Monday|        32.3|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df = spark.sql(query)\n",
    "data_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a88a6e92-22bf-4201-a119-b8984ed7e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data_df.randomSplit([0.8,0.2], seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ff19c-9804-4375-acfd-0e69f27aa51d",
   "metadata": {},
   "source": [
    "# 파이프라인 생성\n",
    "- 전처리 과정을 각 스테이지로 정의해서 쌓는다\n",
    "- 범주형] StringIndexer+onehotencoding : 'pickup_location_id', 'dropoff_location_id', 'day_of_week'\n",
    "- 수치형] StandardScaler : 'passenger_count', 'trip_distance', 'pickup_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2849fce0-a438-497a-881e-d7262c31c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7de8d38f-c906-4658-b111-fb038eb109ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_7b022c005e72,\n",
       " OneHotEncoder_4b6524673046,\n",
       " StringIndexer_84d5e108de22,\n",
       " OneHotEncoder_9f6aa9695f65,\n",
       " StringIndexer_e29455f5f2d3,\n",
       " OneHotEncoder_61ad2dfc7458]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "cat_features = ['pickup_location_id', 'dropoff_location_id', 'day_of_week']\n",
    "for cat in cat_features:\n",
    "    cat_index = StringIndexer(inputCol=cat, outputCol=cat+'_idx').setHandleInvalid('keep')\n",
    "    onehot_encode = OneHotEncoder(inputCols= [cat_index.getOutputCol()], #_idx col\n",
    "                                  outputCols=[cat+'_onehot'] #postfix\n",
    "                                 )\n",
    "    stages += [cat_index, onehot_encode ] #collist\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e63879-4a29-405f-9a69-e2e02247bca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75252491-2f50-4066-9152-6dab9546146c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2fb86-8126-40be-9f6b-fa5c69041f27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
